{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap2 Classifying with scikit-learn Estimators"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "• Estimators: This is to perform classification, clustering, and regression\n",
    "• Transformers: This is to perform preprocessing and data alterations\n",
    "• Pipelines: This is to put together your workflow into a replicable format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn estimators\n",
    "\n",
    "• fit(): This performs the training of the algorithm and sets internal\n",
    "parameters. It takes two inputs, the training sample dataset and the\n",
    "corresponding classes for those samples.\n",
    "\n",
    "• predict(): This predicts the class of the testing samples that is given as\n",
    "input. This function returns an array with the predictions of each input\n",
    "testing sample."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nearest neighbors is perhaps one of the most intuitive algorithms in the set of\n",
    "standard data mining algorithms. To predict the class of a new sample, we look\n",
    "through the training dataset for the samples that are most similar to our new sample.\n",
    "We take the most similar sample and predict the class that the majority of those\n",
    "samples have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ionosphere Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quantum\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "import os\n",
    "print os.path.expanduser('~')\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quantum\\Documents\\Practice for Data Analysis\\Learning Data Mining with Python\\Ionosphere\\ionosphere.data\n"
     ]
    }
   ],
   "source": [
    "data_filename=os.path.join(\n",
    "'C:\\Users\\quantum\\Documents\\Practice for Data Analysis\\Learning Data Mining with Python','Ionosphere','ionosphere.data')\n",
    "print data_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=np.zeros((351,34),dtype='float')\n",
    "y=np.zeros((351,),dtype='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ionosphere.data','r') as input_file:\n",
    "    reader=csv.reader(input_file) \n",
    "    for i, row in enumerate(reader):\n",
    "        # Get the data, converting each item to a float\n",
    "        data = [float(datum) for datum in row[:-1]]\n",
    "        # Set the appropriate row in our dataset\n",
    "        X[i] = data\n",
    "        # 1 if the class is 'g', 0 otherwise\n",
    "        y[i] = row[-1] == 'g'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Moving towards a standard workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First, we need to create these training and testing sets. As before, import and run the\n",
    "#train_test_split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(X,y,random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''import the nearest neighbor class and create an instance for it'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "estimator=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_neighbors=5, p=2, weights='uniform')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''fit it on our training dataset'''\n",
    "estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuancy is 86.4%\n"
     ]
    }
   ],
   "source": [
    "'''train the algorithm with our test set and evaluate with our testing set'''\n",
    "y_predicted=estimator.predict(X_test)\n",
    "accurancy=np.mean(y_test==y_predicted)*100\n",
    "print 'The accuancy is {0:.1f}%'.format(accurancy) \n",
    "#This scores 86.4 percent accuracy, which is impressive for a default algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The procedure is as follows:\n",
    "1. Split the entire dataset into a number of sections called folds.\n",
    "2. For each fold in the dataset, execute the following steps:\n",
    "°° Set that fold aside as the current testing set\n",
    "°° Train the algorithm on the remaining folds\n",
    "°° Evaluate on the current testing set\n",
    "3. Report on all the evaluation scores, including the average score.\n",
    "4. In this process, each sample is used in the testing set only once.\n",
    "This reduces (but doesn't completely eliminate) the likelihood of\n",
    "choosing lucky testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy is 82.3%\n"
     ]
    }
   ],
   "source": [
    "scores=cross_val_score(estimator,X,y,scoring='accuracy')\n",
    "average_accuracy=np.mean(scores)*100\n",
    "print(\"The average accuracy is {0:.1f}%\".format(average_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
